{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_detecting_and_embeddings_with dlib.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNC_BNFA5D4_",
        "colab_type": "text"
      },
      "source": [
        "# Face detection and embeddings collecting\n",
        "This is one of test tasks for some company, where I should make a system for face detecting and collecting embeddings, based on dlib instruments. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1obSFgm5dgq",
        "colab_type": "text"
      },
      "source": [
        "## Preparatory part\n",
        "\n",
        "### Import (or install and import) necessary libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXHYaLe4F16J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEBUG = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TLoZB5i4_xg",
        "colab_type": "code",
        "outputId": "f7373c27-09b1-4626-f649-92eff3aca231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1207
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import bz2\n",
        "import cv2\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import load_model \n",
        "\n",
        "try:\n",
        "    import dlib\n",
        "    if DEBUG:\n",
        "        print(\"All libs are installed\")\n",
        "except:\n",
        "    if DEBUG:\n",
        "        print(\"Installing the required libraries\")\n",
        "  \n",
        "    # dlib installation\n",
        "    !apt update\n",
        "    !apt install -y cmake\n",
        "    !pip install dlib\n",
        "    import dlib\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Installing the required libraries\n",
            "Hit:1 http://security.ubuntu.com/ubuntu artful-security InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu artful InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu artful-updates InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu artful-backports InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "All packages are up to date.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cmake-data libarchive13 libjsoncpp1 liblzo2-2 librhash0 libuv1\n",
            "Suggested packages:\n",
            "  ninja-build lrzip\n",
            "The following NEW packages will be installed:\n",
            "  cmake cmake-data libarchive13 libjsoncpp1 liblzo2-2 librhash0 libuv1\n",
            "0 upgraded, 7 newly installed, 0 to remove and 0 not upgraded.\n",
            "Need to get 4,930 kB of archives.\n",
            "After this operation, 25.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu artful/main amd64 cmake-data all 3.9.1-1 [1,276 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu artful/main amd64 liblzo2-2 amd64 2.08-1.2 [48.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu artful/main amd64 libarchive13 amd64 3.2.2-3.1 [289 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu artful/main amd64 libjsoncpp1 amd64 1.7.4-3 [73.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu artful/main amd64 librhash0 amd64 1.3.4-3 [77.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu artful/main amd64 libuv1 amd64 1.9.1-3 [58.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu artful/main amd64 cmake amd64 3.9.1-1 [3,107 kB]\n",
            "Fetched 4,930 kB in 1s (2,930 kB/s)\n",
            "Selecting previously unselected package cmake-data.\n",
            "(Reading database ... 18408 files and directories currently installed.)\n",
            "Preparing to unpack .../0-cmake-data_3.9.1-1_all.deb ...\n",
            "Unpacking cmake-data (3.9.1-1) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../1-liblzo2-2_2.08-1.2_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.08-1.2) ...\n",
            "Selecting previously unselected package libarchive13:amd64.\n",
            "Preparing to unpack .../2-libarchive13_3.2.2-3.1_amd64.deb ...\n",
            "Unpacking libarchive13:amd64 (3.2.2-3.1) ...\n",
            "Selecting previously unselected package libjsoncpp1:amd64.\n",
            "Preparing to unpack .../3-libjsoncpp1_1.7.4-3_amd64.deb ...\n",
            "Unpacking libjsoncpp1:amd64 (1.7.4-3) ...\n",
            "Selecting previously unselected package librhash0.\n",
            "Preparing to unpack .../4-librhash0_1.3.4-3_amd64.deb ...\n",
            "Unpacking librhash0 (1.3.4-3) ...\n",
            "Selecting previously unselected package libuv1:amd64.\n",
            "Preparing to unpack .../5-libuv1_1.9.1-3_amd64.deb ...\n",
            "Unpacking libuv1:amd64 (1.9.1-3) ...\n",
            "Selecting previously unselected package cmake.\n",
            "Preparing to unpack .../6-cmake_3.9.1-1_amd64.deb ...\n",
            "Unpacking cmake (3.9.1-1) ...\n",
            "Setting up libuv1:amd64 (1.9.1-3) ...\n",
            "Setting up cmake-data (3.9.1-1) ...\n",
            "Setting up librhash0 (1.3.4-3) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up liblzo2-2:amd64 (2.08-1.2) ...\n",
            "Setting up libjsoncpp1:amd64 (1.7.4-3) ...\n",
            "Setting up libarchive13:amd64 (3.2.2-3.1) ...\n",
            "Setting up cmake (3.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Collecting dlib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/8d/e4ddf60452e2fb1ce3164f774e68968b3f110f1cb4cd353235d56875799e/dlib-19.16.0.tar.gz (3.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.3MB 7.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: dlib\n",
            "  Running setup.py bdist_wheel for dlib ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ce/f9/bc/1c51cd0b40a2b5dfd46ab79a73832b41e7c3aa918a508154f0\n",
            "Successfully built dlib\n",
            "Installing collected packages: dlib\n",
            "Successfully installed dlib-19.16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-fcbsNc53ZE",
        "colab_type": "text"
      },
      "source": [
        "### Check existing of weights files in cloud dir. If it's not exist, download and unpack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfGbN9Jx6GM9",
        "colab_type": "code",
        "outputId": "2057bac8-6130-4ab6-b421-14e64ebcd1ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "face_detector_weights = os.path.isfile(\"mmod_human_face_detector.dat.bz2\")\n",
        "facenet_model         = os.path.isfile(\"facenet_keras.h5\")\n",
        "\n",
        "if face_detector_weights and facenet_model:\n",
        "    if DEBUG:\n",
        "        print(\"Model exist\")\n",
        "else:\n",
        "    if DEBUG:\n",
        "        print(\"Downloading weights\")\n",
        "    # Download pretrained cnn_face_detection_model_v1 from dlib and facenet\n",
        "    !wget \"http://dlib.net/files/mmod_human_face_detector.dat.bz2\"\n",
        "    !wget -O facenet_keras.h5 \"https://s185f.storage.yandex.net/rdisk/594789e50af533c4dae873280d755d113dad36c805811b890b42b8c7adb395cb/5bb1a171/xiCnyZq0qx6g-h6yIY-VdMjxvJjJ7MyF6tI5sedijBh4gG6evns74XjMPwBKjqmpUhXcwQ66NZ_XEP2PLLH1mw==?uid=437831410&filename=facenet_keras.h5&disposition=attachment&hash=&limit=0&content_type=application%2Fx-hdf&fsize=92397640&hid=75f38b2414140fcc52f40ca5659a7462&media_type=data&tknv=v2&etag=d4169b76ead0a7a58c5ba7ca4c0b505b&rtoken=a3jIiqUtznsb&force_default=yes&ycrid=na-d9b081e66c7333a7855196900263f819-downloader10e&ts=577232da67e40&s=4e5d3092ea0a89eb38107b34e8fa2ffd1e7b2764035b94cd052581aacac56a48&pb=U2FsdGVkX1_nCthRxfzMl_utdUzktNGlJPzh-IjhWru80fQknF9xrqx3DyGGs7Ji5_4RtTRGBFzcDcH9ZZAyRCRddZTGNa_OxLTqBf1nmMU\"\n",
        "\n",
        "# Unpack and save cnn face detector from dlib\n",
        "!bzip2 -dk \"mmod_human_face_detector.dat.bz2\" \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading weights\n",
            "\n",
            "Redirecting output to ‘wget-log’.\n",
            "\n",
            "Redirecting output to ‘wget-log.1’.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jydfhaRmfu7",
        "colab_type": "code",
        "outputId": "4eb34825-d7e1-4838-8c9b-099d3ce0b59e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Optional part for garbage collection in notebook dirrectory\n",
        "\n",
        "# !rm fa* mm* wg*\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "facenet_keras.h5\t      mmod_human_face_detector.dat.bz2\twget-log\n",
            "mmod_human_face_detector.dat  sample_data\t\t\twget-log.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMU_Nlxz7jOX",
        "colab_type": "text"
      },
      "source": [
        "#### Data standartization from FaceNet predict\n",
        "Code of function from https://github.com/nyoki-mtl/keras-facenet/blob/master/notebook/demo-images.ipynb "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h6pdYK7lrxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prewhiten(x):\n",
        "    if x.ndim == 4:\n",
        "        axis = (1, 2, 3)\n",
        "        size = x[0].size\n",
        "    elif x.ndim == 3:\n",
        "        axis = (0, 1, 2)\n",
        "        size = x.size\n",
        "    else:\n",
        "        raise ValueError('Dimension should be 3 or 4')\n",
        "\n",
        "    mean = np.mean(x, axis=axis, keepdims=True)\n",
        "    std = np.std(x, axis=axis, keepdims=True)\n",
        "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
        "    y = (x - mean) / std_adj\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8pe_XuNWZFL",
        "colab_type": "text"
      },
      "source": [
        "## Image downlader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDbTfc9-WZTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_downloader():\n",
        "    \"\"\"\n",
        "    This function allows you to download n images with using its url.\n",
        "    To complete adding photos just press enter with empty input\n",
        "    \n",
        "    :return: list of images as numpy arrays\n",
        "    \"\"\"\n",
        "    \n",
        "    imgs = []\n",
        "    loop = True\n",
        "    while loop:\n",
        "        url = input(\"Type url here: \")\n",
        "\n",
        "        if DEBUG and not url:\n",
        "            url  = \"https://cs.pikabu.ru/post_img/big/2013/12/16/7/1387185457_631216170.jpg\"\n",
        "#             url  = \"http://www.fotovam.ru/para/kalug/1.jpg\"\n",
        "            loop = False\n",
        "            \n",
        "        if not url:\n",
        "            loop = False\n",
        "            break\n",
        "        img = Image.open(requests.get(url, stream=True).raw)\n",
        "        img = np.asarray(img)\n",
        "        imgs.append(img)\n",
        "\n",
        "    if DEBUG:\n",
        "        plt.figure(figsize=(20,10))\n",
        "        columns = 5\n",
        "        for i, image in enumerate(imgs):\n",
        "            plt.subplot(len(imgs) / columns + 1, columns, i + 1)\n",
        "            plt.grid(False)\n",
        "            plt.imshow(image)\n",
        "    print(\" You download {} photos\".format(len(imgs)))\n",
        "    \n",
        "    if len(imgs) == 0: ValueError: print(\"Sorry. There are no photos for detecting. It's unnecessary to execute code.\")\n",
        "    \n",
        "    return imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD5vyQo27bWu",
        "colab_type": "text"
      },
      "source": [
        "## Class for face detection system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbj50QgfeCCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FaceDetection():\n",
        "    \n",
        "    if DEBUG:\n",
        "        def __init__(self, det, nn):\n",
        "        # Initialize face detector and FaceNet\n",
        "            self.cnn_dlib_face_detector = det\n",
        "            self.face_net = nn     \n",
        "    else:\n",
        "        def __init(self):\n",
        "            self.cnn_dlib_face_detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat')\n",
        "            self.face_net = load_model(\"facenet_keras.h5\")\n",
        "        \n",
        "    def _get_faces(self, img, size):\n",
        "        \"\"\"\n",
        "        :param img: (numpy array) take image (w,h,ch)\n",
        "        :param size: (int) number of pixels (width, height) used in cropping\n",
        "        :return: bounding boxes of faces in the photo\n",
        "        \"\"\"\n",
        "        faces_coord = self.cnn_dlib_face_detector(img, 1)\n",
        "        \n",
        "        if DEBUG:\n",
        "            crop_img = []\n",
        "        # loop over detected faces\n",
        "        faces = []\n",
        "        for face in faces_coord:\n",
        "            x = face.rect.left()\n",
        "            y = face.rect.top()\n",
        "            w = face.rect.right() - x\n",
        "            h = face.rect.bottom() - y\n",
        "            margin = 10\n",
        "            cropped = img[y-margin//2:y+h+margin//2, x-margin//2:x+w+margin//2, :]\n",
        "            aligned = Image.fromarray(np.uint8(cropped)).resize((160,160))\n",
        "\n",
        "            # normalize and append\n",
        "            faces.append(prewhiten(np.asarray(aligned)))\n",
        "\n",
        "            if DEBUG: \n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 3)\n",
        "                crop_img.append(cropped)\n",
        "        if DEBUG:\n",
        "            columns = 5\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            for i, image in enumerate(crop_img):\n",
        "                plt.subplot(len(crop_img) / columns + 1, columns, i + 1)\n",
        "                plt.grid(False)\n",
        "                plt.imshow(image)\n",
        "        \n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.grid(False)\n",
        "            plt.imshow(img)\n",
        "\n",
        "        return faces\n",
        "     \n",
        "    def get_embeddings(self, img, size=160):\n",
        "        \"\"\"\n",
        "        :param img: (numpy array) take image (w,h,ch)\n",
        "        :param size: (int) number of pixels (width, height) used in cropping \n",
        "        :return: (numpy array) embedding from FaceNet, (int) number of faces found in the photo \n",
        "        \"\"\"\n",
        "        faces = self._get_faces(img, size)\n",
        "        embeddings = []\n",
        "        for face in faces:\n",
        "            face = face.reshape((1, size, size, 3))\n",
        "            emb = self.face_net.predict(face)\n",
        "            embeddings.append(emb)\n",
        "\n",
        "        return embeddings\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "582qjUk68C_9",
        "colab_type": "text"
      },
      "source": [
        "## Practical part\n",
        "- Initialize detector (with CNN for face detection and FaceNet for embeddings)\n",
        "- Download images from its urls\n",
        "- Find faces in each photo and append embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU83q-5-PLZs",
        "colab_type": "code",
        "outputId": "ed4f8b21-35d7-42a1-aea5-7d4c471cd967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "if DEBUG:\n",
        "    cnn_dlib_face_detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat')\n",
        "    face_net = load_model(\"facenet_keras.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdTp4wLmlWlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if DEBUG:\n",
        "    detector = FaceDetection(cnn_dlib_face_detector, face_net)\n",
        "\n",
        "else:\n",
        "    detector = FaceDetection()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNjQE5dRi68j",
        "colab_type": "code",
        "outputId": "62502610-c3b9-4027-e25e-5da027453eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "size = 160\n",
        "imgs = image_downloader()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type url here: http://www.fotovam.ru/para/kalug/1.jpg\n",
            "Type url here: \n",
            " You download 1 photos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGuru6ghi7Su",
        "colab_type": "code",
        "outputId": "6d14e2a0-5757-4086-b819-3fbe9d4a227a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emb = []\n",
        "for idx, img in enumerate(imgs):\n",
        "    embeddings = detector.get_embeddings(img, size)\n",
        "    emb.append(embeddings)\n",
        "    print(\"On {} photo {} faces founded\".format(idx+1, len(emb[idx])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On 1 photo 9 faces founded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHVTz67p7L6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}